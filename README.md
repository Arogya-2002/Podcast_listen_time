# ğŸµ Podcast Listening Time Prediction

A machine learning-based system that predicts how long a user is likely to listen to a podcast episode, based on episode metadata. This project includes a complete pipeline from data ingestion to a deployable prediction API.

---

## ğŸ§  Objective

Build a regression model that estimates `Listening_Time_minutes` for podcast episodes using structured metadata like title, podcast ID, duration, and more.

---

## âš™ï¸ Features

* Modular, production-grade ML pipeline
* Structured exception handling
* Data preprocessing, cleaning, and transformation
* Prediction via REST API (FastAPI)
* CORS-enabled for integration with web frontends
* Well-organized project structure

---

## ğŸ“‚ Pipeline Flow

```
Raw CSV File
    â†“
Data Ingestion
    â†“
Data Preprocessing (handle missing values, outliers, zero values)
    â†“
Data Transformation (encoding, scaling, dropping irrelevant features)
    â†“
Model Inference (prediction using trained model)
    â†“
Output: JSON with predicted listening time
```

---

## ğŸ”º Project Structure

```bash
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ data_ingestion.py          # Loads and validates input data
â”‚   â”œâ”€â”€ data_preprocessing.py      # Handles missing data, zero values, outliers
â”‚   â”œâ”€â”€ data_transformation.py     # Encodes categorical variables, drops unnecessary columns
â”œâ”€â”€ constants/
â”‚   â””â”€â”€ __init__.py                # Centralized constants for filenames, paths, etc.
â”œâ”€â”€ entity/
â”‚   â”œâ”€â”€ config_entity.py           # Pipeline configuration schema
â”‚   â”œâ”€â”€ artifact_entity.py         # Artifact structures for component output
â”œâ”€â”€ exceptions/
â”‚   â””â”€â”€ __init__.py                # Custom exception class with stack trace logging
â”œâ”€â”€ logger.py                      # Configures logging for the pipeline
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ prediction_pipeline.py     # Runs full prediction pipeline on input data
app.py                             # FastAPI app for serving predictions
```

---

## ğŸ”¢ Key Components

### 1. `data_ingestion.py`

* Validates the existence of input CSV
* Returns a data artifact containing the file path

### 2. `data_preprocessing.py`

* `fill_missing_values()` - fills nulls with appropriate strategies
* `replace_zero_values()` - replaces invalid zero values
* `types_of_columns()` - detects numeric and categorical columns
* `remove_outliers()` - removes outliers using IQR

### 3. `data_transformation.py`

* `label_encoding()` - label encodes Title and Podcast columns
* `other_columns_encoding()` - encodes other categorical fields
* `drop_unwanted_columns()` - removes original string-based columns

### 4. `prediction_pipeline.py`

* Loads `model.pkl`
* Applies preprocessing and transformation on the uploaded file
* Makes predictions and maps them to the corresponding ID

### 5. `app.py`

* Exposes `/predict/` API endpoint
* Accepts CSV via `multipart/form-data`
* Returns top 10 predictions in JSON

---

## ğŸ”¢ Target Column

The model predicts:

```text
Listening_Time_minutes
```

---

## ğŸš¨ Error Handling

* Custom error class `CustomException` is used across the codebase.
* Provides detailed traceback, filename, and line number for easier debugging.

---

## ğŸŒ API Endpoint

### Start the Server

```bash
uvicorn app:app --reload
```

### Prediction Endpoint

```
POST /predict/
```

* **Consumes:** CSV file (`multipart/form-data`)
* **Returns:** JSON with `ID` and predicted `Listening_Time_minutes`

---

## ğŸ“„ Input File Format

Required columns in CSV:

```
id, Podcast, Title, Duration, ...
```

---

## ğŸ”§ Configuration & Constants

Defined in `src/constants/__init__.py`

Important Constants:

* `DATA_FILE_NAME`: input file name
* `SCHEMA_FILE_PATH`: path to schema YAML
* `SAVED_MODEL_DIR`: location where model is saved
* `MODEL_FILE_NAME`: trained model filename

---

## ğŸ“‚ Requirements

Install all dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ“§ Contact

**Author:** Vamshi
For queries or contributions, feel free to reach out.

---

## ğŸ”¹ Pipeline Diagram

```
+-------------------+
|  Raw Input CSV    |
+-------------------+
          |
          v
+------------------------------+
|     Data Ingestion           |
| (check file exists, load)    |
+------------------------------+
          |
          v
+------------------------------+
|    Data Preprocessing        |
| (fill missing, zero, outliers)|
+------------------------------+
          |
          v
+------------------------------+
|   Data Transformation        |
| (encode categorical vars)    |
+------------------------------+
          |
          v
+------------------------------+
|       Model Prediction       |
|   (load model.pkl & predict) |
+------------------------------+
          |
          v
+------------------------------+
|     Output JSON Response     |
|   [ID, Predicted Time]       |
+------------------------------+
```
